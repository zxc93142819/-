{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 178, 3)\n",
      "(218, 178, 3)\n",
      "[253 229 191 253 229 191 253 229 191 253 229 191 253 229 191 253 229 191\n",
      " 253 229]\n"
     ]
    }
   ],
   "source": [
    "input_path = './input_scunet_color_25'\n",
    "train_image_list = sorted([os.path.join(input_path, f) for f in os.listdir(input_path) if f.endswith('.jpg')])\n",
    "# print(train_image_list)\n",
    "\n",
    "for path in train_image_list :\n",
    "    i = Image.open(path).convert('RGB')\n",
    "    image = cv2.imread(path)\n",
    "    print(image.shape)\n",
    "    # print(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    print(image.shape)\n",
    "    # print(image)\n",
    "    array = np.array(image).flatten()\n",
    "    print(array[:20])\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index    0    1    2    3    4    5    6    7    8  ...  116402  116403  \\\n",
      "0       0  255  229  192  255  229  192  255  229  192  ...      20     120   \n",
      "0       1   69   55   46   68   54   45   69   52   45  ...      92     138   \n",
      "0       2  254  254  254  255  255  255  255  255  255  ...      92      95   \n",
      "0       3   68   59   52  125  116  109   98   89   82  ...      90      58   \n",
      "0       4  153  201  203  152  200  202  152  200  204  ...     201     144   \n",
      "..    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...     ...   \n",
      "0     495  255  255  255  255  255  255  255  255  255  ...     114     159   \n",
      "0     496  226   96   72  226   96   72  226   96   72  ...     147     223   \n",
      "0     497  126   82   35  127   83   36  127   83   36  ...     133      33   \n",
      "0     498   75   72   65   75   72   65   74   71   64  ...     231     242   \n",
      "0     499    1    1    1    1    1    1    1    1    1  ...      56      53   \n",
      "\n",
      "    116404  116405  116406  116407  116408  116409  116410  116411  \n",
      "0       51      20     120      51      22     121      52      23  \n",
      "0      108      98     139     112     105     143     118     111  \n",
      "0       95      93      97      96      94      98      97      95  \n",
      "0       57      52      32      29      22      32      29      22  \n",
      "0      200     201     144     200     201     144     200     201  \n",
      "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
      "0      170     112     154     164     101     166     177     111  \n",
      "0      171     147     223     169     143     222     168     142  \n",
      "0      104     132      34     104     130      35     105     131  \n",
      "0      241     239     249     248     244     252     251     247  \n",
      "0       58      54      51      53      48      51      53      48  \n",
      "\n",
      "[500 rows x 116413 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame([])\n",
    "index = 0\n",
    "for path in train_image_list :\n",
    "    i = Image.open(path).convert('RGB')\n",
    "    array = np.array(i).flatten()\n",
    "    dict = {\"index\" : [index] }\n",
    "    index += 1\n",
    "    for j in range(178 * 218 * 3) :\n",
    "        dict[j] = array[j]\n",
    "    d = pd.DataFrame( dict )\n",
    "    data = pd.concat([data , d] , axis = 0)\n",
    "\n",
    "data.sort_values(by = [\"index\"] , na_position = \"first\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index    0    1    2    3    4    5    6    7    8  ...  116402  116403  \\\n",
      "0       0  255  233  196  255  233  196  255  233  196  ...      23     116   \n",
      "0       1   67   52   45   67   52   45   67   52   45  ...      93     138   \n",
      "0       2  255  255  255  255  255  255  255  255  255  ...      94      94   \n",
      "0       3   53   46   40  106   99   93   90   83   77  ...      84      54   \n",
      "0       4  151  198  206  152  199  207  151  200  205  ...     200     145   \n",
      "..    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...     ...   \n",
      "0     495  255  255  255  255  255  255  255  255  255  ...     120     170   \n",
      "0     496  230   98   75  229   97   74  229   97   74  ...     143     220   \n",
      "0     497  129   85   38  129   85   38  129   85   38  ...     131      35   \n",
      "0     498   75   75   65   74   74   64   74   74   66  ...     234     245   \n",
      "0     499    4    4    4    4    4    4    3    3    3  ...      53      47   \n",
      "\n",
      "    116404  116405  116406  116407  116408  116409  116410  116411  \n",
      "0       49      22     117      50      24     116      50      24  \n",
      "0      105      98     139     111     107     138     113     108  \n",
      "0       92      95      94      92      95      94      92      95  \n",
      "0       53      49      30      31      25      30      31      25  \n",
      "0      199     201     144     198     200     144     198     200  \n",
      "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
      "0      181     123     160     171     113     166     177     117  \n",
      "0      162     142     220     161     143     220     161     143  \n",
      "0      102     131      34     103     132      33     102     131  \n",
      "0      244     240     250     249     244     249     250     244  \n",
      "0       48      50      44      48      49      45      49      50  \n",
      "\n",
      "[500 rows x 116413 columns]\n"
     ]
    }
   ],
   "source": [
    "input_path = './ttt_SCUnet_finetune_epochs20'\n",
    "train_image_list = sorted([os.path.join(input_path, f) for f in os.listdir(input_path) if f.endswith('.jpg')])\n",
    "data = pd.DataFrame([])\n",
    "index = 0\n",
    "for path in train_image_list :\n",
    "    i = Image.open(path).convert('RGB')\n",
    "    array = np.array(i).flatten()\n",
    "    dict = {\"index\" : [index] }\n",
    "    index += 1\n",
    "    for j in range(178 * 218 * 3) :\n",
    "        dict[j] = array[j]\n",
    "    d = pd.DataFrame( dict )\n",
    "    data = pd.concat([data , d] , axis = 0)\n",
    "\n",
    "data.sort_values(by = [\"index\"] , na_position = \"first\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"test.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Params number: 9662892\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from thop import profile\n",
    "from einops import rearrange \n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "\n",
    "\n",
    "class WMSA(nn.Module):\n",
    "    \"\"\" Self-attention module in Swin Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, head_dim, window_size, type):\n",
    "        super(WMSA, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.head_dim = head_dim \n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.n_heads = input_dim//head_dim\n",
    "        self.window_size = window_size\n",
    "        self.type=type\n",
    "        self.embedding_layer = nn.Linear(self.input_dim, 3*self.input_dim, bias=True)\n",
    "\n",
    "        # TODO recover\n",
    "        # self.relative_position_params = nn.Parameter(torch.zeros(self.n_heads, 2 * window_size - 1, 2 * window_size -1))\n",
    "        self.relative_position_params = nn.Parameter(torch.zeros((2 * window_size - 1)*(2 * window_size -1), self.n_heads))\n",
    "\n",
    "        self.linear = nn.Linear(self.input_dim, self.output_dim)\n",
    "\n",
    "        trunc_normal_(self.relative_position_params, std=.02)\n",
    "        self.relative_position_params = torch.nn.Parameter(self.relative_position_params.view(2*window_size-1, 2*window_size-1, self.n_heads).transpose(1,2).transpose(0,1))\n",
    "\n",
    "    def generate_mask(self, h, w, p, shift):\n",
    "        \"\"\" generating the mask of SW-MSA\n",
    "        Args:\n",
    "            shift: shift parameters in CyclicShift.\n",
    "        Returns:\n",
    "            attn_mask: should be (1 1 w p p),\n",
    "        \"\"\"\n",
    "        # supporting sqaure.\n",
    "        attn_mask = torch.zeros(h, w, p, p, p, p, dtype=torch.bool, device=self.relative_position_params.device)\n",
    "        if self.type == 'W':\n",
    "            return attn_mask\n",
    "\n",
    "        s = p - shift\n",
    "        attn_mask[-1, :, :s, :, s:, :] = True\n",
    "        attn_mask[-1, :, s:, :, :s, :] = True\n",
    "        attn_mask[:, -1, :, :s, :, s:] = True\n",
    "        attn_mask[:, -1, :, s:, :, :s] = True\n",
    "        attn_mask = rearrange(attn_mask, 'w1 w2 p1 p2 p3 p4 -> 1 1 (w1 w2) (p1 p2) (p3 p4)')\n",
    "        return attn_mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass of Window Multi-head Self-attention module.\n",
    "        Args:\n",
    "            x: input tensor with shape of [b h w c];\n",
    "            attn_mask: attention mask, fill -inf where the value is True; \n",
    "        Returns:\n",
    "            output: tensor shape [b h w c]\n",
    "        \"\"\"\n",
    "        if self.type!='W': x = torch.roll(x, shifts=(-(self.window_size//2), -(self.window_size//2)), dims=(1,2))\n",
    "        x = rearrange(x, 'b (w1 p1) (w2 p2) c -> b w1 w2 p1 p2 c', p1=self.window_size, p2=self.window_size)\n",
    "        h_windows = x.size(1)\n",
    "        w_windows = x.size(2)\n",
    "        # sqaure validation\n",
    "        # assert h_windows == w_windows\n",
    "\n",
    "        x = rearrange(x, 'b w1 w2 p1 p2 c -> b (w1 w2) (p1 p2) c', p1=self.window_size, p2=self.window_size)\n",
    "        qkv = self.embedding_layer(x)\n",
    "        q, k, v = rearrange(qkv, 'b nw np (threeh c) -> threeh b nw np c', c=self.head_dim).chunk(3, dim=0)\n",
    "        sim = torch.einsum('hbwpc,hbwqc->hbwpq', q, k) * self.scale\n",
    "        # Adding learnable relative embedding\n",
    "        sim = sim + rearrange(self.relative_embedding(), 'h p q -> h 1 1 p q')\n",
    "        # Using Attn Mask to distinguish different subwindows.\n",
    "        if self.type != 'W':\n",
    "            attn_mask = self.generate_mask(h_windows, w_windows, self.window_size, shift=self.window_size//2)\n",
    "            sim = sim.masked_fill_(attn_mask, float(\"-inf\"))\n",
    "\n",
    "        probs = nn.functional.softmax(sim, dim=-1)\n",
    "        output = torch.einsum('hbwij,hbwjc->hbwic', probs, v)\n",
    "        output = rearrange(output, 'h b w p c -> b w p (h c)')\n",
    "        output = self.linear(output)\n",
    "        output = rearrange(output, 'b (w1 w2) (p1 p2) c -> b (w1 p1) (w2 p2) c', w1=h_windows, p1=self.window_size)\n",
    "\n",
    "        if self.type!='W': output = torch.roll(output, shifts=(self.window_size//2, self.window_size//2), dims=(1,2))\n",
    "        return output\n",
    "\n",
    "    def relative_embedding(self):\n",
    "        cord = torch.tensor(np.array([[i, j] for i in range(self.window_size) for j in range(self.window_size)]))\n",
    "        relation = cord[:, None, :] - cord[None, :, :] + self.window_size -1\n",
    "        # negative is allowed\n",
    "        return self.relative_position_params[:, relation[:,:,0].long(), relation[:,:,1].long()]\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, head_dim, window_size, drop_path, type='W', input_resolution=None):\n",
    "        \"\"\" SwinTransformer Block\n",
    "        \"\"\"\n",
    "        super(Block, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        assert type in ['W', 'SW']\n",
    "        self.type = type\n",
    "        if input_resolution <= window_size:\n",
    "            self.type = 'W'\n",
    "\n",
    "        print(\"Block Initial Type: {}, drop_path_rate:{:.6f}\".format(self.type, drop_path))\n",
    "        self.ln1 = nn.LayerNorm(input_dim)\n",
    "        self.msa = WMSA(input_dim, input_dim, head_dim, window_size, self.type)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.ln2 = nn.LayerNorm(input_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4 * input_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * input_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.msa(self.ln1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.ln2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvTransBlock(nn.Module):\n",
    "    def __init__(self, conv_dim, trans_dim, head_dim, window_size, drop_path, type='W', input_resolution=None):\n",
    "        \"\"\" SwinTransformer and Conv Block\n",
    "        \"\"\"\n",
    "        super(ConvTransBlock, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        self.trans_dim = trans_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.window_size = window_size\n",
    "        self.drop_path = drop_path\n",
    "        self.type = type\n",
    "        self.input_resolution = input_resolution\n",
    "\n",
    "        assert self.type in ['W', 'SW']\n",
    "        if self.input_resolution <= self.window_size:\n",
    "            self.type = 'W'\n",
    "\n",
    "        self.trans_block = Block(self.trans_dim, self.trans_dim, self.head_dim, self.window_size, self.drop_path, self.type, self.input_resolution)\n",
    "        self.conv1_1 = nn.Conv2d(self.conv_dim+self.trans_dim, self.conv_dim+self.trans_dim, 1, 1, 0, bias=True)\n",
    "        self.conv1_2 = nn.Conv2d(self.conv_dim+self.trans_dim, self.conv_dim+self.trans_dim, 1, 1, 0, bias=True)\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "                nn.Conv2d(self.conv_dim, self.conv_dim, 3, 1, 1, bias=False),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(self.conv_dim, self.conv_dim, 3, 1, 1, bias=False)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_x, trans_x = torch.split(self.conv1_1(x), (self.conv_dim, self.trans_dim), dim=1)\n",
    "        conv_x = self.conv_block(conv_x) + conv_x\n",
    "        trans_x = Rearrange('b c h w -> b h w c')(trans_x)\n",
    "        trans_x = self.trans_block(trans_x)\n",
    "        trans_x = Rearrange('b h w c -> b c h w')(trans_x)\n",
    "        res = self.conv1_2(torch.cat((conv_x, trans_x), dim=1))\n",
    "        x = x + res\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SCUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_nc=3, config=[2,2,2,2,2,2,2], dim=64, drop_path_rate=0.0, input_resolution=256):\n",
    "        super(SCUNet, self).__init__()\n",
    "        self.config = config\n",
    "        self.dim = dim\n",
    "        self.head_dim = 32\n",
    "        self.window_size = 8\n",
    "\n",
    "        # drop path rate for each layer\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(config))]\n",
    "\n",
    "        self.m_head = [nn.Conv2d(in_nc, dim, 3, 1, 1, bias=False)]\n",
    "\n",
    "        begin = 0\n",
    "        self.m_down1 = [ConvTransBlock(dim//2, dim//2, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution) \n",
    "                      for i in range(config[0])] + \\\n",
    "                      [nn.Conv2d(dim, 2*dim, 2, 2, 0, bias=False)]\n",
    "\n",
    "        begin += config[0]\n",
    "        self.m_down2 = [ConvTransBlock(dim, dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution//2)\n",
    "                      for i in range(config[1])] + \\\n",
    "                      [nn.Conv2d(2*dim, 4*dim, 2, 2, 0, bias=False)]\n",
    "\n",
    "        begin += config[1]\n",
    "        self.m_down3 = [ConvTransBlock(2*dim, 2*dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW',input_resolution//4)\n",
    "                      for i in range(config[2])] + \\\n",
    "                      [nn.Conv2d(4*dim, 8*dim, 2, 2, 0, bias=False)]\n",
    "\n",
    "        begin += config[2]\n",
    "        self.m_body = [ConvTransBlock(4*dim, 4*dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution//8)\n",
    "                    for i in range(config[3])]\n",
    "\n",
    "        begin += config[3]\n",
    "        self.m_up3 = [nn.ConvTranspose2d(8*dim, 4*dim, 2, 2, 0, bias=False),] + \\\n",
    "                      [ConvTransBlock(2*dim, 2*dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW',input_resolution//4)\n",
    "                      for i in range(config[4])]\n",
    "                      \n",
    "        begin += config[4]\n",
    "        self.m_up2 = [nn.ConvTranspose2d(4*dim, 2*dim, 2, 2, 0, bias=False),] + \\\n",
    "                      [ConvTransBlock(dim, dim, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution//2)\n",
    "                      for i in range(config[5])]\n",
    "                      \n",
    "        begin += config[5]\n",
    "        self.m_up1 = [nn.ConvTranspose2d(2*dim, dim, 2, 2, 0, bias=False),] + \\\n",
    "                    [ConvTransBlock(dim//2, dim//2, self.head_dim, self.window_size, dpr[i+begin], 'W' if not i%2 else 'SW', input_resolution) \n",
    "                      for i in range(config[6])]\n",
    "\n",
    "        self.m_tail = [nn.Conv2d(dim, in_nc, 3, 1, 1, bias=False)]\n",
    "\n",
    "        self.m_head = nn.Sequential(*self.m_head)\n",
    "        self.m_down1 = nn.Sequential(*self.m_down1)\n",
    "        self.m_down2 = nn.Sequential(*self.m_down2)\n",
    "        self.m_down3 = nn.Sequential(*self.m_down3)\n",
    "        self.m_body = nn.Sequential(*self.m_body)\n",
    "        self.m_up3 = nn.Sequential(*self.m_up3)\n",
    "        self.m_up2 = nn.Sequential(*self.m_up2)\n",
    "        self.m_up1 = nn.Sequential(*self.m_up1)\n",
    "        self.m_tail = nn.Sequential(*self.m_tail)  \n",
    "        #self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x0):\n",
    "\n",
    "        h, w = x0.size()[-2:]\n",
    "        paddingBottom = int(np.ceil(h/64)*64-h)\n",
    "        paddingRight = int(np.ceil(w/64)*64-w)\n",
    "        x0 = nn.ReplicationPad2d((0, paddingRight, 0, paddingBottom))(x0)\n",
    "\n",
    "        x1 = self.m_head(x0)\n",
    "        x2 = self.m_down1(x1)\n",
    "        x3 = self.m_down2(x2)\n",
    "        x4 = self.m_down3(x3)\n",
    "        x = self.m_body(x4)\n",
    "        x = self.m_up3(x+x4)\n",
    "        x = self.m_up2(x+x3)\n",
    "        x = self.m_up1(x+x2)\n",
    "        x = self.m_tail(x+x1)\n",
    "\n",
    "        x = x[..., :h, :w]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "model = SCUNet()\n",
    "\n",
    "# model = SCUNet(in_nc=3,config=[4,4,4,4,4,4,4],dim=64)\n",
    "\n",
    "model.load_state_dict(torch.load(\"./Unet_epochs20.pth\"), strict=True)\n",
    "# model.load_state_dict(torch.load(model_path), strict=True)\n",
    "# model.eval()\n",
    "# for k, v in model.named_parameters():\n",
    "    # v.requires_grad = False\n",
    "# model = model.to(device)\n",
    "# logger.info('Model path: {:s}'.format(model_path))\n",
    "number_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
    "print('Params number: {}'.format(number_parameters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
